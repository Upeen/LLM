# Ollama local API
OLLAMA_URL = "http://localhost:11434/api/generate"

# Best lightweight open-source model
MODEL_NAME = "mistral"

# Generation defaults
TEMPERATURE = 0.7
MAX_TOKENS = 512
